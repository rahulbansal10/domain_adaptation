{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_FeatureExtractor(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(VGG_FeatureExtractor, self).__init__()\n",
    "    model_vgg = models.vgg16(pretrained=True)\n",
    "    self.features = model_vgg.features\n",
    "    self.avgpool = model.avgpool\n",
    "    self.classifier = model_vgg.classifier[0:3]\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    x = self.avgpool(x)\n",
    "    x = x.view(x.size(0), 25088)\n",
    "    x = self.classifier(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class office_loader(Dataset):\n",
    "    def __init__(self, root= \"/home/iacvr/dataset/\", name = \"office/amazon_10_list.txt\", transform=None):\n",
    "        self.path = root + name\n",
    "        with open(self.path,\"r\") as file:\n",
    "            self.data = [(Image.open(path.split()[0]).convert(\"RGB\"), int(path.split()[1])) for path in file.readlines()]\n",
    "        self.transform = transform\n",
    "        file.close()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx][0], self.data[idx][1]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = np.asarray(img).transpose((2, 0, 1))\n",
    "            img = torch.tensor(np.asarray(img))\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_dataset(Dataset):\n",
    "    def __init__(self, features, labels, transform=None):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self,idx):\n",
    "        feature, label = self.features[idx], self.labels[idx]\n",
    "        return torch.tensor(feature), label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeImage():\n",
    "    def __init__(self, size):\n",
    "      if isinstance(size, int):\n",
    "        self.size = (int(size), int(size))\n",
    "      else:\n",
    "        self.size = size\n",
    "    def __call__(self, img):\n",
    "      th, tw = self.size\n",
    "      return img.resize((th, tw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(resize_size=224, crop_size=224):\n",
    "  normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "  return  transforms.Compose([\n",
    "        ResizeImage(resize_size),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(G, data_loader):  # G is the feature extractor\n",
    "    X = np.zeros((1,4096))\n",
    "    Y = np.zeros((1), dtype= int)\n",
    "    for images, labels in data_loader:\n",
    "        features = G(images).data.numpy()\n",
    "        labels = labels.numpy()\n",
    "        X = np.concatenate((X,features), axis=0)\n",
    "        Y = np.concatenate((Y,labels), axis=0)\n",
    "    return X[1:], Y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = F.softmax(x, dim=1) * F.log_softmax(x, dim=1)\n",
    "        b = -1.0 * b.sum(dim=1)\n",
    "        return b.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class content_module(nn.Module):\n",
    "    def __init__(self, feat_dim=4096, num_classes=31):\n",
    "        super(content_module, self).__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.fc1 = nn.Linear(self.feat_dim,int(self.feat_dim/4))\n",
    "        self.fc2 = nn.Linear(int(self.feat_dim/4), self.num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_1 = F.relu(self.fc1(x))\n",
    "        content = F.relu(self.fc2(h_1))\n",
    "        return content\n",
    "\n",
    "class style_module(nn.Module):\n",
    "    def __init__(self, feat_dim=4096, style_dim = 100):\n",
    "        super(style_module, self).__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.style_dim = style_dim\n",
    "        self.fc1 = nn.Linear(self.feat_dim, int(self.feat_dim/4))\n",
    "        self.fc2 = nn.Linear(int(self.feat_dim/4), self.style_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_1 = F.relu(self.fc1(x))\n",
    "        style = F.relu(self.fc2(h_1))\n",
    "        return style\n",
    "\n",
    "class reconstruction(nn.Module):\n",
    "    def __init__(self, feat_dim=4096, num_classes = 31, style_dim = 100):\n",
    "        super(reconstruction, self).__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.style_dim = style_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.input_dim = style_dim + num_classes\n",
    "        self.fc1 = nn.Linear(self.input_dim, int(self.feat_dim/4))\n",
    "        self.fc2 = nn.Linear(int(self.feat_dim/4), self.feat_dim)\n",
    "    \n",
    "    def forward(self, content, style):\n",
    "        m = nn.Softmax(dim=1)\n",
    "        x = torch.cat((m(content), style), 1)\n",
    "        h_1 = F.relu(self.fc1(x))\n",
    "        h_2 = F.relu(self.fc2(h_1))\n",
    "        return h_2\n",
    "\n",
    "class adv_classifier_module(nn.Module):\n",
    "    def __init__(self, num_classes=31, style_dim = 100):\n",
    "        super(adv_classifier_module, self).__init__()\n",
    "        self.style_dim = style_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.fc1 = nn.Linear(self.style_dim, self.num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = F.relu(self.fc1(x))\n",
    "        return logits\n",
    "\n",
    "class domain_identifier_module(nn.Module):\n",
    "    def __init__(self, feat_dim = 4096):\n",
    "        super(domain_identifier_module, self).__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.fc1 = nn.Linear(self.feat_dim, int(self.feat_dim/4))\n",
    "        self.fc2 = nn.Linear(int(self.feat_dim/4), int(self.feat_dim/16))\n",
    "        self.fc3 = nn.Linear(int(self.feat_dim/16), 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_1 = F.relu(self.fc1(x))\n",
    "        h_2 = F.relu(self.fc2(h_1))\n",
    "        h_3 = F.relu(self.fc3(h_2))\n",
    "        return h_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [],
   "source": [
    "class training_protocol():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train_domain_identifier_module(self, data_loader, DI, epochs):\n",
    "        print(\"Training domain identifier module\")\n",
    "        loss_ = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(DI.parameters(), lr = 0.003)\n",
    "        epoch_loss = list()\n",
    "        for epoch in range(epochs):\n",
    "            batch_loss = list()\n",
    "            for i, data in enumerate(data_loader, 0):\n",
    "                inputs, labels = data[0].float(), data[1]\n",
    "                logits = DI(inputs)\n",
    "                optimizer.zero_grad()\n",
    "                loss = loss_(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # print statistics\n",
    "                batch_loss.append(loss.item())\n",
    "\n",
    "            if(epoch%5==0):\n",
    "                print(\"epoch {} : Classification Loss {:2f}\".format(epoch, np.mean(batch_loss)))\n",
    "        print('Finished Training')\n",
    "                \n",
    "    def train_content_module(self, data_loader, C, epochs):\n",
    "        print(\"Training Content Separator\")\n",
    "        loss_ = nn.CrossEntropyLoss()\n",
    "        params = list(C.parameters())\n",
    "        optimizer = optim.SGD(params, lr = 0.004)\n",
    "        epoch_loss = list()\n",
    "        for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "            batch_loss = list()\n",
    "            for i, data in enumerate(data_loader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data[0].float(), data[1]\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                content = C(inputs)\n",
    "                loss = loss_(content, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # print statistics\n",
    "                batch_loss.append(loss.item())\n",
    "\n",
    "            if(epoch%5==0):\n",
    "                print(\"epoch {} : Classification Loss {:2f}\".format(epoch, np.mean(batch_loss)))\n",
    "        print('Finished Training')\n",
    "    \n",
    "    def train_style_module(self, data_loader, C, S, R, adv_clf, epochs):\n",
    "        print(\"Training Style Separator\")\n",
    "        loss_mse = nn.MSELoss()\n",
    "        loss_cent = nn.CrossEntropyLoss()\n",
    "        loss_ent = HLoss()\n",
    "        params = list(S.parameters()) + list(R.parameters()) + list(adv_clf.parameters())\n",
    "        optimizer = optim.Adam(params)\n",
    "          \n",
    "        epoch_adv_loss, epoch_rec_loss = list(), list()\n",
    "        for epoch in range(epochs):  #loop over the dataset multiple times\n",
    "            batch_adv_loss, batch_rec_loss, batch_ent_loss = list(), list(), list()\n",
    "            for i, data in enumerate(data_loader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data[0].float(), data[1]\n",
    "                # forward + backward + optimize\n",
    "                optimizer.zero_grad()\n",
    "                content = C(inputs).detach()\n",
    "                style = S(inputs)\n",
    "                inputs_hat = R(content, style)\n",
    "                logits = adv_clf(style)\n",
    "                loss1 = loss_mse(inputs, inputs_hat)\n",
    "                loss2 = -loss_ent((logits))\n",
    "                loss = loss1 + loss2\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                batch_rec_loss.append(loss1.item())\n",
    "                batch_adv_loss.append(loss2.item())\n",
    "        \n",
    "            if(epoch%5==0):\n",
    "                print(\"epoch {} : Adversarial Loss {:2f} Reconstruction Loss {:2f}\".format(epoch, np.mean(batch_adv_loss),np.mean(batch_rec_loss)))   \n",
    "        print('Finished Training')\n",
    "    \n",
    "    def test_content(self, data_loader, C):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in data_loader:\n",
    "                features, labels = data[0].float(), data[1]\n",
    "                content = C(features)\n",
    "                m = nn.Softmax(dim=1)\n",
    "                outputs = m(content)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(\"Accuracy of the network on the data: {:2f}\".format(100 * (correct / total)))\n",
    "    \n",
    "    def test_style(self, data_loader, S, adv_clf):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in data_loader:\n",
    "                features, labels = data[0].float(), data[1]\n",
    "                style = S(features)\n",
    "                logits = adv_clf(style)\n",
    "                m = nn.Softmax(dim=1)\n",
    "                outputs = m(logits)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(\"Accuracy of the network on the data: {:2f}\".format(100 * (correct / total)))\n",
    "    \n",
    "    def check_confidence(self, inputs, Ct, confidence, source_index_dict, source_features):\n",
    "        x = Ct(inputs).detach()\n",
    "        m = nn.Softmax(dim=1)\n",
    "        x = m(x)\n",
    "        values, indices = torch.max(x, 1)\n",
    "        classes = list()\n",
    "        source_inputs = torch.tensor([])\n",
    "        target_inputs = torch.tensor([])\n",
    "        for i in range(len(values)):\n",
    "            if values[i]>=confidence:\n",
    "                c = random.choice(source_index_dict[indices[i].item()])\n",
    "                source_inputs = torch.cat((source_inputs, torch.tensor([source_features[c]]).float()), 0)\n",
    "                target_inputs = torch.cat((target_inputs, inputs[i].unsqueeze(0)), 0)\n",
    "        return source_inputs, target_inputs\n",
    "    \n",
    "    def train(self, source_index_dict, source_features, source_labels, target_loader, Cs, Ss, Rs, Ct, St, Rt, DI, epochs):\n",
    "        print(\"Training\")\n",
    "        loss_ = nn.CrossEntropyLoss()\n",
    "        loss_mse = nn.MSELoss()\n",
    "        optimizer = optim.SGD([{\"params\":Ct.parameters(), \"lr\": 0.001},{\"params\":St.parameters(), \"lr\": 0.0},{\"params\":Rt.parameters(), \"lr\": 0.0},{\"params\":DI.parameters(), \"lr\": 0.0}])\n",
    "        epoch_loss = list()\n",
    "        for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "            batch_loss = list()\n",
    "            for i, data in enumerate(target_loader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, _ = data[0].float(), data[1]\n",
    "                source_inputs, target_inputs = self.check_confidence(inputs, Ct, 0.9, source_index_dict, source_features)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                if(len(source_inputs)==0):\n",
    "                    continue\n",
    "                source_content, source_style = Cs(source_inputs).detach(), Ss(source_inputs).detach()\n",
    "                target_content, target_style = Ct(target_inputs), St(target_inputs)\n",
    "                #X1, y1 = Rt(source_content, target_style), torch.tensor(np.zeros(len(source_inputs)), dtype = int)\n",
    "                X2, y2 = Rt(target_content, source_style), torch.tensor(np.ones(len(source_inputs)), dtype = int)\n",
    "                logits = DI(X2)\n",
    "                loss = loss_(logits, y2)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # print statistics\n",
    "                batch_loss.append(loss.item())\n",
    "\n",
    "            if(epoch%5==0):\n",
    "                print(\"epoch {} : Classification Loss {:2f}\".format(epoch, np.mean(batch_loss)))\n",
    "        print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transform_data()\n",
    "# source = office_loader(name = \"office/amazon_31_list.txt\", transform = transform)\n",
    "# target = office_loader(name = \"office/webcam_31_list.txt\", transform = transform)\n",
    "# source_loader = DataLoader(source, batch_size = 64,shuffle = True)\n",
    "# target_loader = DataLoader(target, batch_size = 64,shuffle = True)\n",
    "# G = VGG_FeatureExtractor()\n",
    "# source_features, source_labels = get_features(G, source_loader)\n",
    "# target_features, target_labels = get_features(G, target_loader)\n",
    "\n",
    "# features = np.concatenate([source_features, target_features], axis = 0)\n",
    "# labels = np.concatenate([source_labels, target_labels], axis = 0)\n",
    "\n",
    "# domain_features = np.concatenate([source_features, target_features], axis = 0)\n",
    "# domain_source_features = source_features\n",
    "# domain_target_features = target_features\n",
    "# domain_labels = np.concatenate([np.ones(len(source_features), dtype = int), np.zeros(len(target_features), dtype = int)])\n",
    "# domain_source_labels = np.ones(len(source_features), dtype = int)\n",
    "# domain_target_labels = np.zeros(len(target_features), dtype = int)\n",
    "\n",
    "# domain_features_train, domain_features_test, domain_labels_train, domain_labels_test = train_test_split(domain_features, domain_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_dataset = feature_dataset(features, labels)\n",
    "# source_features_dataset = feature_dataset(source_features, source_labels)\n",
    "# target_features_dataset = feature_dataset(target_features, target_labels)\n",
    "\n",
    "# features_loader = DataLoader(features_dataset, batch_size = 32, shuffle = True)\n",
    "# source_features_loader = DataLoader(source_features_dataset, batch_size = 32, shuffle = True)\n",
    "# target_features_loader = DataLoader(target_features_dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "# domain_features_train_dataset = feature_dataset(domain_features_train, domain_labels_train)\n",
    "# domain_features_test_dataset = feature_dataset(domain_features_test, domain_labels_test)\n",
    "\n",
    "# domain_features_train_loader = DataLoader(domain_features_train_dataset, batch_size = 32, shuffle = True)\n",
    "# domain_features_test_loader = DataLoader(domain_features_test_dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "# domain_source_features_dataset = feature_dataset(domain_source_features, domain_source_labels)\n",
    "# domain_target_features_dataset = feature_dataset(domain_target_features, domain_target_labels)\n",
    "\n",
    "# domain_source_features_loader = DataLoader(domain_source_features_dataset, batch_size = 32, shuffle = True)\n",
    "# domain_target_features_loader = DataLoader(domain_target_features_dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "# source_index_dict = {}\n",
    "# target_index_dict = {}\n",
    "# for i in range(31):\n",
    "#     source_index_dict[i] = np.where(source_labels==i)[0]\n",
    "#     target_index_dict[i] = np.where(target_labels==i)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cs = content_module()\n",
    "# Ss = style_module()\n",
    "# Rs = reconstruction()\n",
    "# adv_clf = adv_classifier_module()\n",
    "\n",
    "# Ct = content_module()\n",
    "# St = style_module()\n",
    "# Rt = reconstruction()\n",
    "\n",
    "# DI = domain_identifier_module()\n",
    "\n",
    "ti = training_protocol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ti.train_content_module(data_loader = source_features_loader, C = Cs, epochs=100)\n",
    "# ti.train_style_module(data_loader = features_loader, C = Cs, S = Ss, R = Rs, adv_clf = adv_clf, epochs=500)\n",
    "# ti.train_domain_identifier_module(data_loader = domain_features_train_loader, DI = DI, epochs = 100)\n",
    "# Ct.load_state_dict(Cs.state_dict())\n",
    "# St.load_state_dict(Ss.state_dict())\n",
    "# Rt.load_state_dict(Rs.state_dict())\n",
    "# ti.train(source_index_dict, source_features, source_labels, target_features_loader, Cs, Ss, Rs, Ct, St, Rt, DI, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the data: 61.132075\n"
     ]
    }
   ],
   "source": [
    "ti.test_content(data_loader = target_features_loader, C = Ct)\n",
    "# ti.test_style(data_loader = source_features_loader, S = Ss, adv_clf = adv_clf)\n",
    "# ti.test_content(data_loader = domain_source_features_loader, C = DI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(795, 4096)\n",
      "795\n",
      "Accuracy of the network on the data: 95.094340\n"
     ]
    }
   ],
   "source": [
    "content = Cs(torch.tensor(target_features).float())\n",
    "style = Ss(torch.tensor(target_features).float())\n",
    "features_hat = Rs(content, style).data.numpy()\n",
    "print(features_hat.shape)\n",
    "features_hat_dataset = feature_dataset(features_hat, domain_target_labels)\n",
    "print(len(features_hat_dataset))\n",
    "features_hat_loader = DataLoader(features_hat_dataset, batch_size = 32, shuffle = True)\n",
    "ti.test_content(data_loader = features_hat_loader, C = DI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968503937007874\n",
      "0.15974842767295597\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(target_features[0:794]).float()\n",
    "labels = torch.tensor(target_labels[0:794])\n",
    "x = Cs(inputs).detach()\n",
    "m = nn.Softmax(dim=1)\n",
    "x = m(x)\n",
    "values, indices = torch.max(x, 1)\n",
    "p = ((indices==labels))\n",
    "q = (values>0.95)\n",
    "labels_q = labels[q]\n",
    "indices_q = indices[q]\n",
    "print((labels_q==indices_q).sum().item()/q.sum().item())\n",
    "print(q.sum().item()/len(target_features))\n",
    "# classes = list()\n",
    "# source_inputs = torch.tensor([])\n",
    "# target_inputs = torch.tensor([])\n",
    "# for i in range(len(values)):\n",
    "#     if values[i]>=0.1:\n",
    "#         c = random.choice(source_index_dict[indices[i].item()])\n",
    "#         source_inputs = torch.cat((source_inputs, torch.tensor([source_features[c]]).float()), 0)\n",
    "#         target_inputs = torch.cat((target_inputs, inputs[i].unsqueeze(0)), 0)\n",
    "# print(source_inputs.shape)\n",
    "# print(target_inputs.shape)\n",
    "# print(len(source_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(83.2145)\n",
      "tensor(73.4068)\n",
      "tensor(1534.3530)\n",
      "tensor(1534.3533)\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "x = source_features_dataset[569][0].float()\n",
    "content = Cs(x).detach().unsqueeze(0)\n",
    "style = Ss(x).detach().unsqueeze(0)\n",
    "x_hat = Rs(content, style).detach().squeeze()\n",
    "print(x.norm(p=2))\n",
    "print(x_hat.norm(p=2))\n",
    "print(((x-x_hat).norm(p=2))**2)\n",
    "print(F.mse_loss(x,x_hat, reduction='mean')*4096)\n",
    "print(x)\n",
    "print(x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaptiveAvgPool2d(output_size=(7, 7))\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "print(model.avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1: requires_grad = True , gradient: tensor([[0.3403, 0.0636, 0.9248, 0.2385, 0.7509]])\n",
      "p2: requires_grad = False , gradient: None\n",
      "\n",
      "p1: requires_grad = True , gradient: tensor([[0.7751, 0.0997, 0.7676, 0.2848, 0.0819]])\n",
      "p2: requires_grad = False , gradient: None\n",
      "\n",
      "p1: requires_grad = False , gradient: tensor([[0., 0., 0., 0., 0.]])\n",
      "p2: requires_grad = True , gradient: tensor([[0.0499, 0.1877, 0.8539, 0.5193, 0.5678]])\n",
      "\n",
      "p1: requires_grad = False , gradient: tensor([[0., 0., 0., 0., 0.]])\n",
      "p2: requires_grad = True , gradient: tensor([[0.2056, 0.0416, 0.5869, 0.0693, 0.1369]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "n_dim = 5\n",
    "\n",
    "p1 = nn.Linear(n_dim, 1)\n",
    "p2 = nn.Linear(n_dim, 1)\n",
    "\n",
    "optimizer = optim.Adam(list(p1.parameters())+list(p2.parameters()))\n",
    "p2.weight.requires_grad = False\n",
    "for i in range(4):\n",
    "    dummy_loss = (p1(torch.rand(n_dim)) + p2(torch.rand(n_dim))).squeeze()\n",
    "    optimizer.zero_grad()\n",
    "    dummy_loss.backward()\n",
    "    optimizer.step()\n",
    "    print('p1: requires_grad =', p1.weight.requires_grad, ', gradient:', p1.weight.grad)\n",
    "    print('p2: requires_grad =', p2.weight.requires_grad, ', gradient:', p2.weight.grad)\n",
    "    print()\n",
    "\n",
    "    if i == 1:\n",
    "        p1.weight.requires_grad = False\n",
    "        p2.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[3.0,3.0,3.0],[3.0,3.0,3.0]])\n",
    "y = torch.tensor([[1.0,1.0,1.0],[1.0,1.0,1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24.)"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(x,y, reduction =\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 3]),)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([10,15,26,15])\n",
    "print(np.where(a==15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
